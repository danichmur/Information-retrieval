{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zd2eOTKp2BhE"
   },
   "source": [
    "## Домашнее задание 5\n",
    "\n",
    "В данном домашнем задании Вам предстоит обучить нейронную модель лучше ранжировать документы на последней стадии поиска. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-qt0KohA2HSD"
   },
   "source": [
    "### 1. Датасет\n",
    "Для обучения вам предоставляется файл train.tsv в формате аналогичном queries.tsv, используйте эти пары (запрос, документ) в качестве положительных примеров. Отрицательные примеры подберите на своё усмотрение. Используйте полученные в предыдущих домашних работах тексты статей википедии как входные данные для документа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "19riNLOm2hbq"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from typing import Dict, List, Tuple\n",
    "ArticleName = str\n",
    "Text = str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GeDylm-R2cTi"
   },
   "outputs": [],
   "source": [
    "def load_queries(queries_fn: ArticleName) -> List[Tuple[Text, ArticleName]]:\n",
    "    queries = []\n",
    "    for line in open(queries_fn, encoding='utf8'):\n",
    "        query, answer = line.rstrip().split('\\t', 1)\n",
    "        queries.append((query, answer))\n",
    "    return queries\n",
    "\n",
    "train = load_queries(\"./train.tsv\")    \n",
    "for query, article_name in train[:5]:\n",
    "    print(f'{query} -> {article_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-clY1ZcU2sSz"
   },
   "source": [
    "### 2. Обучение\n",
    "Используйте готовую предобученную BERT-оподобную модель в качестве основы. Дообучите её на задачу бинарной классификации - предсказания того, является ли документ релевантным запросу.\n",
    "Рекомендую пользоваться библиотекой transformers ([документация](https://huggingface.co/transformers/)). Она поддерживает pytorch и tensorflow, содержит репозиторий предобученных моделей.\n",
    "Рекомендую использовать [colab](https://colab.research.google.com/drive/1dGF9gyPgqTqlAfUHbreL3EtXgPMtJs5h?usp=sharing) с настройками среды GPU, чтобы ускорить обучение и применение.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9AFoEex5nieM"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Us1hFf5inq5w"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "batch = [[\"the most common wave forms of ac is\", \"Waveform\"],\n",
    "         [\"how many seats did labour win in 2015\", \"2015 United Kingdom general election\"],\n",
    "         [\"who won the soccer game monterrey or tigres\", \"Tigres UANL\"],\n",
    "         [\"capital and largest city of belarus on the svislach river\", \"Minsk\"]]\n",
    "encoded_input = tokenizer(batch, padding=True, return_tensors='tf')\n",
    "for ids in encoded_input['input_ids']:\n",
    "  print(ids)\n",
    "  print(tokenizer.convert_ids_to_tokens(ids))\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ij87NEtqoykW"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#  CODE HERE\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m-N216Ag3njm"
   },
   "source": [
    "### 3. Поиск\n",
    "Используйте предсказания модели для переранжирования лучших N документов, полученных при поиске BM25. Сравните качество полученного алгоритма поиска при разных значения N (10, 25, 50).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jGamy6KN3qZy"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#  CODE HERE\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rv7kE_CQ3rJV"
   },
   "source": [
    "### 4. Оптимизация применения (+1 балл)\n",
    "Обучите BERT-опободную нейронную модель в [сиамской схеме](https://www.researchgate.net/profile/Laure_Soulier/publication/304350730/figure/download/fig1/AS:376342722957320@1466738505636/General-architecture-of-the-DSSM-network.png), аналогичной DSSM, когда запросная и документная часть считаются независимо, и связываются только в конце через косинус.\n",
    "Предпрочитайте векторные представления для запросов и документов, требуемых для оценки качества.\n",
    "Сравните качество и скорость полученной модели с предыдущим пунктом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XPmHcTSx3uu7"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#  CODE HERE\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hw5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
